{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_id_list = reuters.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_id = list(filter(lambda x: x.startswith(\"train\"),\n",
    "                            document_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = [reuters.raw(doc_id) for doc_id in document_id_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STOCKS\\n  A survey of 19 provinces and seven cities\\n  showed vermin consume between seven and 12 pct of China's grain\\n  stocks, the China Daily said.\\n      It also said that each year 1.575 mln tonnes, or 25 pct, of\\n  China's fruit output are left to rot, and 2.1 mln tonnes, or up\\n  to 30 pct, of its vegetables. The paper blamed the waste on\\n  inadequate storage and bad preservation methods.\\n      It said the government had launched a national programme to\\n  reduce waste, calling for improved technology in storage and\\n  preservation, and greater production of additives. The paper\\n  gave no further details.\\n  \\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -i INPUT -d DICTIONARY -p POSTING\n",
      "ipykernel_launcher.py: error: argument -i/--input is required\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magz/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #args = parse_user_args()\n",
    "    \n",
    "    document_id_list = reuters.fileids()\n",
    "\n",
    "def parse_user_args():\n",
    "    arg_parser = argparse.ArgumentParser()\n",
    "    arg_parser.add_argument('-i', '--input', required=True,\n",
    "                            help='directory-of-documents')\n",
    "    arg_parser.add_argument('-d', '--dictionary', required=True,\n",
    "                            help='dictionary-file')\n",
    "    arg_parser.add_argument('-p', '--posting', required=True,\n",
    "                            help='postings-file')\n",
    "    return arg_parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id_list = sorted(os.listdir('/Users/magz/nltk_data/corpora/reuters/training'), key=lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/magz/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/reuters.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '''Good muffins cost $3.88\\nin New (York).  Please (buy) me\\ntwo of them.\\n(Thanks).'''\n",
    "vocabulary = []\n",
    "for sent in sent_tokenize(s):\n",
    "    for word in word_tokenize(sent):\n",
    "        vocabulary.append(stemmer.stem(word).lower())\n",
    "vocab_set = set(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = {}\n",
    "postings = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in vocab_set:\n",
    "    if v in terms:\n",
    "        \n",
    "    else:\n",
    "        postings.append(set())\n",
    "        offset= len(postings)-1\n",
    "        pair = [1, offset]\n",
    "        terms[v] = pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " u'muffin',\n",
       " 'cost',\n",
       " '$',\n",
       " '3.88',\n",
       " 'in',\n",
       " 'new',\n",
       " '(',\n",
       " 'york',\n",
       " ')',\n",
       " '.',\n",
       " u'pleas',\n",
       " '(',\n",
       " 'buy',\n",
       " ')',\n",
       " 'me',\n",
       " 'two',\n",
       " 'of',\n",
       " 'them',\n",
       " '.',\n",
       " '(',\n",
       " u'thank',\n",
       " ')',\n",
       " '.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$': [1, 4],\n",
       " '(': [1, 13],\n",
       " ')': [1, 5],\n",
       " '.': [1, 10],\n",
       " '3.88': [1, 8],\n",
       " 'buy': [1, 16],\n",
       " 'cost': [1, 11],\n",
       " 'good': [1, 3],\n",
       " 'in': [1, 14],\n",
       " 'me': [1, 1],\n",
       " u'muffin': [1, 6],\n",
       " 'new': [1, 15],\n",
       " 'of': [1, 7],\n",
       " u'pleas': [1, 0],\n",
       " u'thank': [1, 12],\n",
       " 'them': [1, 2],\n",
       " 'two': [1, 9],\n",
       " 'york': [1, 17]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
